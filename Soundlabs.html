<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link href="./output.css" rel="stylesheet">
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=Alice&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans&display=swap" rel="stylesheet">    
    <link rel="icon" href="./img/favicon.png">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    <title>Maheen Adhami Soundlabs</title>
    <style>
        #menu-toggle:checked + #menu {
          display:block;  
        }
    </style>
</head>

<body>
    <div class="bg-gradient-to-b from-peach bg-contain pb-0.5"">
        <header class="md:px-16 px-6 flex flex-wrap items-center md:py-0 py-2 ">
            <div class ="flex-1 flex justify-between items-center">
                <p class="text-peach">.</p>
            </div>
                <label for="menu-toggle" class="cursor-pointer md:hidden block"> <img class="w-9 h-auto" src="img/Hamburger menu.svg"></label>
                <input type="checkbox" class="hidden" id="menu-toggle"/>
                <div class=" hidden md:flex md:items=center md:w-auto w-full" id="menu">
                    <nav>
                        <ul class= "md:flex items-center justify-between text-base text-gray-700 text-2xl font-alice pt-4 md:pt-2">
                            <li><a href="./Documents/Resume.pdf" download="Maheen Adhami-Resume" target="_blank" class= "md:p-4 py-3 px-0 block border-b-2 border-transparent hover:border-salmon">Resume</a></li>
                            <li><a href="./index.html" class= "md:p-4 py-3 px-0 block border-b-2 border-transparent hover:border-salmon">Home</a></li>
                        </ul>
                    </nav>
    
                </div>
        </header>
        <div class="md:w-1/2 w-5/6 mx-auto">
            <h2 class="font-alice text-navy-1 text-4xl text-center pt-24 pb-2">Soundlabs</h2>
            <h2 class="font-alice text-navy-1 text-2xl text-center pt-2 pb-5">(under construction)</h2>
            <div class="flex-wrap flex justify-center">
                    <span class="text-m font-opens inline-block py-1 px-5 mx-3 my-1 rounded text-navy-1 border border-navy-1"> Component Library</span>
                    <span class="text-m font-opens inline-block py-1 px-5 mx-3 my-1 rounded text-navy-1 border border-navy-1"> UI Design</span>
                    <span class="text-m font-opens inline-block py-1 px-5 mx-3 my-1 rounded text-navy-1 border border-navy-1"> Interaction Design</span>
            </div>
        </div>
    </div>
    <div class="md:w-1/2 w-5/6 mx-auto bg-white pb-16">
        <h3 class="font-alice text-blue-1 text-xl pt-4">The challenge</h3>
        <p class="pt-3 font-opens text-navy-1">To reduce the cost needed for full-time music composers, especially for amateur or less financially stable mobile game developers
            
        </p>
        <h3 class="font-alice text-blue-1 text-xl pt-4">My role</h3>
        <p class="pt-3 font-opens text-navy-1">Designer</p>
        <h3 class="font-alice text-blue-1 text-xl pt-4">The Team</h3>
        <p class="pt-3 font-opens text-navy-1">2 Designers, 4 Developers</p>
        <h3 class="font-alice text-blue-1 text-xl pt-4">Duration</h3>
        <p class="pt-3 font-opens text-navy-1">May 2020 - August 2020</p>
    </div>
    <div class="bg-gray-100" >
        <div class="md:w-1/2 w-5/6 mx-auto pb-16">
            <h3 class="font-alice text-navy-1 text-3xl pt-16 pb-5">Project Overview</h3>
            <p class="pt-3 font-opens text-navy-1">This course project was centered around using genetic algorithms to create music based off a mood, 
                3 main requirements were given to scope this project out:
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-3/4" src="img/require.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
                Over the course of this term, our team split up the tasks required to develop our project such that
                 each member would be able to contribute using skills that they excel in. My contribution consisted of applying the usability engineering 
                 principles shown to develop a prototype for the front-end of our product in conjunction with Winnie Ren.  
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-3/4" src="img/4aproaches.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
                I began focusing on the user and tasks by utilizing personas created during our design sprint as well as conducting secondary
                 market research to determine a list of requirements and constraints; these were then validated through a needs assessment with
                  our primary user, a game developer. I then applied Neilson’s Usability Heuristics, as well as Wicken’s 13 Principles of Display 
                  Design in an iterative design process to begin developing our prototype. The preliminary ideas were white boarded together and
                   were then created at a higher fidelity using Figma once we had determined the minimum viable product (MVP) for that iteration.
                   We then collected empirical data to evaluate each MVP through usability testing and post-test questionnaires. 
                    These findings were then used to design the next iteration of changes for our product. 
            </p>
        </div>
    </div>
    <div class="md:w-1/2 w-5/6 mx-auto bg-white pb-16">
        <h3 class="font-alice text-navy-1 text-3xl  pt-16 pb-5">The Process </h3>
        <p class="pt-3 font-opens text-navy-1">Our attention was drawn towards the potential target audience of game development companies,
             where the composers at major game companies like Sega are not freelance, work-for-hire “indie artists” in the modern sense, 
             but simply regular, full-time employees. We determined that there was a space for us to reduce the cost needed for full-time
              music composers, especially for amateur or less financially stable mobile game developers.
        </p>
        <h3 class=" w-3/4 mx-auto font-opens text-blue-1 text-center text-xl pt-4">We decided that the best way to approach this problem given our time restrictions would be to begin with a design sprint.  </h3>
    </div>
    <div class="bg-gray-100" >
        <div class="md:w-1/2 w-5/6 mx-auto pb-16">
            <h3 class="font-alice text-navy-1 text-3xl pt-16 pb-5">Day 1: Setting a goal</h3>
            <p class="pt-3 font-opens text-navy-1">
                
            Day 1 began by brainstorming potential questions and “How Might We’s” so that we had a clear goal set
             for the sprint. We each put in all the questions that we had relating to this project, and then 
             categorized them based on general category. Once we had done that, we all voted for the topics 
             that we found the most important
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-3/4" src="img/hmw.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">  
            With that, we then created 4 sprint questions that we would be focusing on and attempting to answer for the remainder of the sprint
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-3/4" src="img/questions.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">  
                The first question allowed us to explore current problems in the industry and help us create a sprint map. From this we voted for a 
                sprint focus, and selected a target user (indie game designers) of the music creation process as well as a target event
                 (getting advice on how to make music geared towards certain feelings) 
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-3/4" src="img/sprintmap.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">  
                Once we had chosen a goal, we ended off the first day of the sprint, and prepared for the next where we would 
                each showcase our own research, and then work individually to create our own solution sketches with items we liked from the demos.
            </p>
        </div>
    </div>
    <div class="md:w-1/2 w-5/6 mx-auto bg-white pb-16">
        <h3 class="font-alice text-navy-1 text-3xl  pt-16 pb-5">Day 2:Researching existing solutions</h3>
        <p class="pt-3 font-opens text-navy-1">
            Due to UX design being my strength, I chose to focus my lightning demo on UI design elements that I believed led to a good user experience
            I chose 2 examples to showcase for my demo and highlighted why the design for each interface worked.  
        </p>
        <img class="mx-auto flex justify-center object-cover py-8 w-3/4" src="img/flatio.png" alt="Flower and sky"/>
        <p class="pt-3 font-opens text-navy-1">
            Overall, Flat.io was an interface that targeted a more experienced user than our target user. The interface provided us with a
             good background on terminology we could use, and methods to organize different music related features. It also served as a
              good base for the different possibilities in modifying music; for example, using crescendos, and different tempos to 
              adjust the dynamics of the song. Another important element that the interface for Flat.io captured well was the 
              placement of their features. There was a clear hierarchy for their features which followed a flat hierarchy system 
              rather than a deep one. This ensured that while there were individual categories, the content within them remained 
              discoverable and did not get buried within multiple sublevels.
        </br></br>
        A similar idea would be useful if applied to our project, where buttons and settings that impact the entire composition are placed 
        above more broken down features. Additionally, ensuring that elements such as collaboration are placed where they are expected due
         other popular interfaces was also an important take away from this demo. In general, many of the tools on Flat.io would allow users 
         to create music from scratch which is not a goal for our particular project
        </p>
        <h3 class=" w-3/4 mx-auto font-opens text-blue-1 text-center text-xl pt-8">
            As a result, they would likely not be helpful in our user interface but would be more useful when thinking about the technical implantation (sprint question 3).
             Values such as tempos, and keys would be useful as backend metrics
        </h3>
        <img class="mx-auto flex justify-center object-cover py-8 w-3/4" src="img/incred.png" alt="Flower and sky"/>
        <p class="pt-3 font-opens text-navy-1 pt-8">
            Incredibox on the other hand was a very simple interface. It turned music composition into a leisure activity or a game. 
            The main element that caught our attention in this demo was the limited sound library. Users were given 20 different 
            pre-existing beats that they could overlay on top of each other. These were beats that could be synchronized together
             while still giving the user creative freedom to create their own mixes. In the context of our project, this could be
              applied by having the genetic algorithm create multiple tracks using individual instruments similar to the beats 
              showcased in Incredibox. This would allow indie game creators to sample and regenerate multiple tracks quickly,
               but at the same time would give them the freedom to adjust their track according to how they would want it by 
               layering multiple instruments. While the visual element of this demo was also appreciated, through a quick cost-benefit 
               analysis, it was decided that 
        </p>
        <h3 class=" w-3/4 mx-auto font-opens text-blue-1 text-center text-xl pt-8">
            visual elements would increase the difficulty of the technical implementation, 
            take up additional screen space, and would not provide meaningful value to the final track composition
        </h3>
        <p class="pt-3 font-opens text-navy-1 pt-8">
            As a result, we decided they would not be applicable to this project.
        </p>
    </div>
    <div class="bg-gray-100" >
        <div class="md:w-1/2 w-5/6 mx-auto pb-16">
            <h3 class="font-alice text-navy-1 text-3xl pt-16 pb-5">Day 3: Deciding the MVP</h3>
            <p class="pt-3 font-opens text-navy-1">
                On the third day of the sprint we each went around and showcased our solution sketches, and product ideas. 
                After the showcasing the solutions, we did multiple rounds of voting, the first round of blue dots involved
                 us creating a heat map of areas we liked best. After that each of the 6 members was given an orange vote to
                  vote for the idea they liked best. And finally an additional red vote was given to a member that was designated
                   as decision maker at the start of the sprint for them to select the final idea. 
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-full" src="img/solsketch.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
                The name of my solution sketch was Adaptively, and it was one of the two solutions that our group picked through heat mapping and voting
            </p>
            <h3 class=" w-3/4 mx-auto font-opens text-blue-1 text-center text-xl pt-8">
                Adaptively was the most front-end focused solution sketch, and therefore highlighted potential solutions to 
                multiple user problems that we had previously been looking at.
            </h3>
            <p class="pt-3 font-opens text-navy-1">
                The track editor in particular had multiple votes due through the heat mapping. A feature that many of my teammates liked was the list of premade 
                “beats” with recommended and not recommended indicators beside them. This was a feature that was appreciated as it focused heavily on our sprint target 
            </p>
            <h3 class=" w-3/4 mx-auto font-opens text-blue-1 text-center text-xl pt-8">
                “How might amateur/indie game designers get advice on how to make music geared towards certain feelings”. 
            </h3>
            <p class="pt-3 font-opens text-navy-1">
                It also helped answer the question “how might we decrease the technical expertise need to create electronic music”.
                 This feature allowed users to be given premade tracks with guidance on what beats correlate best with the mood they
                 had previously selected but also allows the user flexibility to experiment with additional beats and instruments.
                </br></br>
                Another feature that had multiple votes was the feedback screen. This screen would be viewed by users of the game so that they 
                could provide feedback for the soundtrack for the game designer. This process consisted of users being able to listen to the
                soundtrack and answer what mood they believe it best represents through a poll. The results for this would be available on 
                 the track details page for its creator to view. While this feature got multiple votes to begin with, through follow up
                 conversations both within the team, and with the TA, it was decided that the extra feedback would not be feasible to use 
                 through a GA. Dynamic and inconsistent parameters would require advanced optimization techniques in addition to time and 
                  knowledge that was beyond our scope.
                </br></br>
                Finally, the remainder of the votes through the heatmapping were for features that we have saw in other solutions
                or applied in existing popular software interfaces. The “select your mood” was a recurring theme 
                in multiple solution sketches and was voted on primarily to highlight the recurrence.
                Collaboration and version history, on the other hand, were features, we have seen used other places. 
                These were elements that we concluded made the user experience better however they did not answer our main sprint problem. 
                The library page was also seen as a nice to have but not important enough to warrant votes. 
            </br></br>
            Overall, adaptively was used as the base for the front end of our low-fidelity prototype and was used in conjunction 
            with the another solution sketch called Nodes n Tune which provided a better thought out back-end. The strengths of 
            this solutions definitely lied in its user interactions rather than its implementation of GA.
            
        </p>
        c
        <img class="mx-auto flex justify-center object-cover py-8 w-full" src="img/storyboard.png" alt="Flower and sky"/>
    </div>
</div>
<div class="md:w-1/2 w-5/6 mx-auto bg-white pb-16">
        <h3 class="font-alice text-navy-1 text-3xl  pt-16 pb-5">Day 4: Building the MVP</h3>
        <p class="pt-3 font-opens text-navy-1">
            The fourth day was spent developing a low fidelity prototype, this was primarily done by me and one more team member as we had experience in Figma, and it would be done quickly. 
            
        </p>
    </div>
    <img class="mx-auto flex justify-center object-cover py-8 w-3/4" src="img/lfp1.png" alt="Flower and sky"/>  
<div class="bg-gray-100" >
        <div class="md:w-1/2 w-5/6 mx-auto pb-32">
            <h3 class="font-alice text-navy-1 text-3xl pt-16 pb-5">Day 5: The Testing</h3>
            <p class="pt-3 font-opens text-navy-1">
                Finally, on day 5 we focused on testing all of our products between the users
            </br></br>
            My role in the testing process was to be an observer. In particular I focused on flaws in our prototype as
            I was one of the two makers for it. I also focused on writing notes on user behaviour when things went how 
            we expected them to, and when things did not. Key points from 2 users are noted below.  
        </p>
        <img class="mx-auto flex justify-center object-cover py-8 w-full" src="img/User interviews.png" alt="Flower and sky"/>
    </div>
</div>
<div class="md:w-1/2 w-5/6 mx-auto bg-white pb-16">
    <h3 class="font-alice text-navy-1 text-3xl  pt-16 pb-5">Sprint Take aways and moving onto Iteration 2</h3>
    <p class="pt-3 font-opens text-navy-1">
        After completing the sprint process, I believe there were some questions we answered better than others. 
        Due to the design sprint being user centered, we did not determine a clear way to create fitness rules for music.
             We went as far as determining the parameters we would use, these parameters being our temp, stress, and energy 
             values however we did not yet know how we would implement these values. In terms of determining the problems 
             one might experience while creating music (question 1), the main challenges that I believed our users would 
             encounter were the lack of expertise in the music industry. As our target users were indie game developers, 
             they would have pre-existing knowledge from the industry that would help them navigate an unfamiliar software
             . As a result, their challenges would come primarily from not knowing which keys, or tempos relate to certain
             moods better than others. Other problems that I thought would come with music creation were the cost of outsourcing 
             the service, as well as copyright protection on existing melodies. Additionally, despite brainstorming multiple ways
             that we could decrease the technical expertise needed to create music for specific moods, the solution that we chose 
             to test decreased the technical expertise through generating tracks for the user and through suggesting instruments. 
               This was an idea pulled from Adaptively and I believed it pointed the user in the direction of a completed track. 
               It would be the user’s choice if they wished to let the program do the majority of the work or if they wished to 
               customize and edit their track. 
            </br></br>
            Finally, we established that to meet our long-term goal, we need to enable game developers to be produce 
            soundtracks for their game quickly, without the fear of using copyrighted material, and without requiring a musical background
        </br></br>
        As we moved forward in the iterative design process, I believed an important consideration we needed to take into account
        was the types of sounds and instruments we would want to work with. There were multiple issues with the instrument selection page,
        and the size of the instrument library will heavily influence that design. In the user interview with nav
    </p>
    <h3 class=" w-3/4 mx-auto font-opens text-blue-1 text-center text-xl pt-8">
        a point was brought up that this would be a useful tool to creating looping idle music
    </h3>
    <p class="pt-3 font-opens text-navy-1">
        This would be an important use case to incorporate. Finally, would be important to make clearer connections on
         how the back end of the program would work, so that they could be accurately represented on the front end in a 
         user-friendly way. This would be especially important when iterating on the GA controls. 
    </p>
    </div>
    <div class="bg-gray-100" >
        <div class="md:w-1/2 w-5/6 mx-auto pb-32">
            <h3 class="font-alice text-navy-1 text-3xl pt-16 pb-5">Testing our improvements</h3>
        <p class="pt-3 font-opens text-navy-1">
                After the sprint, we split the team in half and got to work on the second iteration. Half the team worked on learning how to implement
                 the backend while my half of the team worked on updating the designs, and incorporating the feedback that we received.
            </br></br>
            The major change that we made was to remove the node map, which was a large point of confusion for many users, 
            we also simplified the mood control by making the user select only one mood for the whole track. 
            Finally we updated the instrument selection to be more clear, and pivoted the design so that a loopable track was created. 
            We also used this as a chance to develop the genetic algorithm component of it, and ensure that the developed prototype 
            and the figma prototype would be similar for our next round of testing. 
        </br></br>
            
            We re-interviewed the same users again and then gave each user a questionnaire to fill out.  
            I then used the user research data we collected to outline 3 major problems with the systems. 
        </p>
        <img class="mx-auto flex justify-center object-cover py-8 w-1/2" src="img/rec1.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
                When the target and mood scale is shifted users found that some values resulted in unexpected behaviour. 
                For small shifts towards either the target or mood ends of the spectrum, users did not notice identifiable changes 
                to the track being played. Additionally, I noted that on the extreme value of 100% target matching, the behaviour was not as expected. 
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-full" src="img/int1.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
                Through a Kano Model test with 5 users. 1 out of 5 users was neutral with the statement “Various ratios of the "Fitness Weight" 
                slider worked for you and it was identifiable to notice the effects” while 2 users stated they somewhat agreed. 
                During the user interviews, these users stated that they primarily struggled with noticing changes at the extreme 
                value of 100% matching target notes. They stated that the expected result was a 100% match of the goal track and 
                were surprised to see that additional notes continued to be generated. Their assumption was that moving it to the 
                target extreme would give them manual control over the track. With the current algorithm, there is a mutation rate 
                that applies to all the values of the slider. A 0% mutation will result in the algorithm getting stuck on a value 
                that may not necessarily reflect the target, as a result a mutation rate is necessary for the regeneration of the track. 
            </p>
            <h3 class="font-opens text-blue-1  text-xl pt-8">
                My Recommendation?
            </h3>
            <p class="pt-3 font-opens text-navy-1">
                As the failure of the extreme values is not a failure of the genetic algorithm
            </p>
            <h3 class="font-opens text-blue-1  text-xl pt-8">
                I do not believe it is necessary to modify the genetic algorithm to reduce the mutation rate for the 100% target match
            </h3>
            <p class="pt-3 font-opens text-navy-1">
                I do however recommend making it more clear to the user what the expected result could be. 
                The first action should be capping the percentage so that a value of 100% cannot be reached. 
                The expected result for this action would be that users will understand that 100% values are not possible and 
                will expect a slight mutation to their target track at the 99% value. The second recommended action is to 
                rename the slider to a more descriptive name and add helper text that explains the functionality of slider.
                This follows the usability heuristic of error prevention
            </p>
            <h3 class="font-opens text-blue-1  text-xl pt-8">
                By doing a better job explaining the resulting consequence of an action, users will be able to form a more accurate mental
                model of the system, and will form action plans that result in fewer mistakes. 
            </h3>
            <img class="mx-auto flex justify-center object-cover py-8 w-1/2" src="img/rec2.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
                The colours used in both the Figma prototype, as well as the Processing prototype resulted in 
                confusion during the user tests. Users found it unclear which colours corresponded to active actions 
                presented in the prototype, and which colours were default, inactive colours. Additionally, due to the 
                similar saturation levels, and low contrast ratios, there were accessibility issues that resulted in
                 colors not being clearly defined for users with color blindless. 
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-full" src="img/int2.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
                Through a Kano Model test with 5 users. 2 out of 5 users somewhat disagreed with the statement
                 “The colors in the soundboard for target and generated track were easy to understand” 
                 while 1 user stated they were neutral. During the user interviews, these users stated that they 
                 had struggled to initially understand which notes were ‘On’ or ‘Off’ on the generated track. They 
                 felt that both colors could indicate an ‘On’ state. One user elaborated that they chose “Somewhat Disagree” 
                 rather than “Strongly Disagree” as the states became clear after observing the prototype for a few seconds.
                  They also stated that the ‘On’ and ‘Off’ states for the ‘Target’ track were clear. This protype was also 
                  tested within our design team with a colour-blind member. They stated that they had a hard time differentiating between
                   the colors used in the generated track in the Processing prototype. Upon looking at the contrast ratios of these colors.
                    The purple and teal had a contrast ratio of 2.16:1 when compared with each other. A minimum contrast ration of 3:1 is 
                    required for functional graphics
            </p>
            <h3 class="font-opens text-blue-1  text-xl pt-8">
                My Recommendation?
            </h3>
            <p class="pt-3 font-opens text-navy-1">
                Based off the pain points discussed, I recommend re-skinning the prototypes 
                so that the colors are more accessible and easier to understand. 
                The most common criticism about the colors used was that the active and inactive states were unclear.
                 Following common design standards, I would suggest using colors with a lower saturation to indicate inactive states.
                  It should also be noted that for inactive graphics, there are no contrast ratio requirements. 
            </p>
            <h3 class="font-opens text-blue-1  text-xl pt-8">
                This will allow users to build mental models consistent with other web apps. 
            </h3>
            <p class="pt-3 font-opens text-navy-1">
                I would also suggest using darker colors for the active states to increase the contrast
            ratio from 2.16 to at least 3:1. The colors used should also try and be friendly for red-green color
            blind users as it is the most common type of color-blindness . Finally, I recommend increasing the font size, 
            and using a darker shade of grey, as the current color does not pass the AA contrast test for both normal and large text.  
            </p>
            <img class="mx-auto flex justify-center object-cover py-8 w-1/2" src="img/rec3.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
            Upon reaching the instrument selection page, users expected to be able to select instruments from a wider library than what they were shown. 
            Users that had tested the initial prototype, Prototype 1, had been given a recommended list of instruments, but also had the option to
            search for more. They recalled this while testing Prototype 3 and excepted the same functionality. 
            </br></br>           
            Through our testing, 3 out of 5 users were returning testers who had previously tested Prototype 1. All 3 of these users had stated that they expected to be able to choose additional instruments. We then used the Kano-Model test to determine how users feel about the addition of this feature, and about the lack of this feature. 
        
        </p>
        <img class="mx-auto flex justify-center object-cover py-8 w-full" src="img/survey.png" alt="Flower and sky"/>
            <p class="pt-3 font-opens text-navy-1">
                The results from this test primarily indicated that this would be a feature that brings 
                delight to the user or may be required. One user that we tested was a mobile developer and was also
                 our primary user for this product. He stated that he expected to be able to change instruments and
                  would have liked to see that functionality as sometimes game designers/ developers have certain 
                  instruments they feel would fit with the mood of the game. He also stated that playing around with
                   various moods to see what instruments are recommended would be a hassle and waste time.
            </p>
            <h3 class="font-opens text-blue-1  text-xl pt-8">
                My Recommendation?
            </h3>
            <p class="pt-3 font-opens text-navy-1">
                Using feedback from our primary user, I suggest allowing users to be able to select multiple instruments for their track, 
                by giving them access to the full instrument library. I also suggest having indicators 
                that show the user which instruments are recommended for the mood that they chose. 
                
            </p>
            <h3 class="font-opens text-blue-1  text-xl pt-8">
                This will allow users to have the freedom to make their own choices without needing to restart the track process, 
                while also guiding them using researched recommendations for what instruments may work for their track.
            </h3>
        </div>
</div>
<div class="md:w-1/2 w-5/6 mx-auto bg-white pb-16">
    <h3 class="font-alice text-navy-1 text-3xl  pt-16 pb-5">The final prototype & Closing thoughts</h3>
    <p class="pt-3 font-opens text-navy-1">
        With this recommendations in place, we went on the make the final changes to the prototype. 
The main improvements for this iteration were the updated colors, an improved instrument selection, and fixing minor issues with the track edit page. 
</br></br>
The final designs looked like this: 

    </p>
    <img class="mx-auto flex justify-center object-cover py-8 w-full" src="img/lfp2.png" alt="Flower and sky"/>
    <h3 class=" w-3/4 mx-auto font-opens text-blue-1 text-center text-xl pt-8">
        And to improve the look and feel of the prototypes, I quickly mocked a potential high fidelity prototype that we could use in the future
    </h3>
    <img class="mx-auto flex justify-center object-cover py-8 w-full" src="img/hfp.png" alt="Flower and sky"/>
    <p class="pt-3 font-opens text-navy-1">
        Due to the current global circumstances, I think this term presented some unique challenges in relation to remote group work, 
        specifically in terms of scheduling work time and finding tools that we could use for the project. To begin, the asynchronous 
        learning of this term resulted in each member having varying schedules that built around our personal lives rather than us all 
        sharing identical class schedules.  We also had team members in Pacific standard time zone which presented challenges in earlier
         hours of the day. This meant that much of our group work was done later in the evening. To be more considerate of the members 
         that did their work earlier, we opted for weekly touch points at a time when all of us were free.
        </br></br>
There were also some challenges presented through the tools we used. The initial sprint was the most difficult,
 as there were not very many real time white boarding applications, which led to lengthier meeting times at the start 
 of the term. There were also issues in coding the GA as there are not many tools for real-time programming. 
 These issues were not found while completing the deliverables, or while creating the front-end prototype as the
  tools we used had real-time collaboration features. In general, to combat these issues we would be on a call
   (and sometimes screen share) with the members we were working with, we found that this allowed instant communication 
   and introduced a collaboration element on tools that otherwise would not have had these capabilities. These methods were not perfect,
    and as a result we found that we were sometimes limited by the resources available. 
The end product however did answer our original design challenge, and resulted in a functional and usable product. 

    </p>
    </div>

    <div class="bg-mustard mx-auto" >
        <p class="s text-center font-alice text-navy-1">
        </br></br>
            Designed and Developed with love by Maheen Adhami 2021
        </br></br></br></br>
        </p>
          
    </div>
    
   </body>
</body>
</html>